import os
import tempfile
import pandas as pd
from datetime import datetime
import streamlit as st

# --- KHU V·ª∞C IMPORT ---
try:
    from langchain_openai import ChatOpenAI
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_chroma import Chroma
    from langchain_core.documents import Document
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.document_loaders import Docx2txtLoader
    from pypdf import PdfReader
    from pdf2image import convert_from_path
    import pytesseract
except ImportError:
    st.error("Thi·∫øu th∆∞ vi·ªán! H√£y ch·∫°y: pip install langchain-chroma langchain-huggingface langchain-google-genai langchain-openai")
    st.stop()

# --- C·∫§U H√åNH H·ªÜ TH·ªêNG ---
TESSERACT_PATH = r"C:\Program Files\Tesseract-OCR\tesseract.exe"
POPPLER_PATH = r"C:\Program Files\poppler-24.08.0\Library\bin"

DB_DIR = "vector_db"
HISTORY_FILE = "file_history.csv"

# C·∫•u h√¨nh Tesseract
if os.path.exists(TESSERACT_PATH):
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_PATH

def extract_text_with_ocr(file_path):
    """ƒê·ªçc file PDF, t·ª± ƒë·ªông chuy·ªÉn sang OCR n·∫øu l√† file scan"""
    text = ""
    try:
        reader = PdfReader(file_path)
        for page in reader.pages:
            extracted = page.extract_text()
            if extracted: text += extracted + "\n"
    except: pass

    # Logic ph√°t hi·ªán file scan
    total_pages = len(reader.pages) if 'reader' in locals() and reader.pages else 1
    if len(text) < 50 * total_pages:
        st.toast("üì∑ ƒêang ch·∫°y OCR (ƒê·ªçc ·∫£nh)...", icon="‚è≥")
        try:
            if not os.path.exists(POPPLER_PATH):
                return "L·ªói: Ch∆∞a c·∫•u h√¨nh ƒë√∫ng ƒë∆∞·ªùng d·∫´n Poppler."
            images = convert_from_path(file_path, dpi=300, poppler_path=POPPLER_PATH)
            ocr_text = ""
            for img in images:
                ocr_text += pytesseract.image_to_string(img, lang='vie+eng') + "\n"
            return ocr_text
        except Exception as e:
            return f"L·ªói OCR: {e}"
    return text

def process_and_save(uploaded_file, meta_info):
    """X·ª≠ l√Ω file v√† l∆∞u v√†o Vector DB"""
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp:
        tmp.write(uploaded_file.getbuffer())
        fpath = tmp.name

    text = ""
    if uploaded_file.name.endswith('.pdf'):
        text = extract_text_with_ocr(fpath)
    elif uploaded_file.name.endswith('.docx'):
        loader = Docx2txtLoader(fpath)
        docs = loader.load()
        text = "\n".join([d.page_content for d in docs])
    elif uploaded_file.name.endswith('.xlsx'):
        try:
            df = pd.read_excel(fpath)
            text = df.to_string(index=False)
        except: pass
    
    os.remove(fpath)
    if not text.strip(): return 0

    full_content = (
        f"METADATA >> [T√™n VB: {meta_info['doc_name']}] | [B·ªô ph·∫≠n: {meta_info['department']}] | [Ng√†y HL: {meta_info['effective_date']}]\n"
        f"N·ªòI DUNG VƒÇN B·∫¢N:\n{text}"
    )
    doc = Document(page_content=full_content, metadata=meta_info)
    
    splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=300)
    splits = splitter.split_documents([doc])

    emb_func = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
    vector_db = Chroma(persist_directory=DB_DIR, embedding_function=emb_func)
    vector_db.add_documents(splits)
    
    log_entry = {
        "File g·ªëc": uploaded_file.name,
        "T√™n vƒÉn b·∫£n": meta_info['doc_name'],
        "ƒê∆°n v·ªã": meta_info['department'],
        "Ng√†y hi·ªáu l·ª±c": str(meta_info['effective_date']),
        "Th·ªùi gian n·∫°p": datetime.now().strftime("%Y-%m-%d %H:%M"),
        "S·ªë ƒëo·∫°n": len(splits)
    }
    
    if os.path.exists(HISTORY_FILE):
        df_hist = pd.read_csv(HISTORY_FILE)
        df_hist = pd.concat([df_hist, pd.DataFrame([log_entry])], ignore_index=True)
    else:
        df_hist = pd.DataFrame([log_entry])
    df_hist.to_csv(HISTORY_FILE, index=False)
    return len(splits)

def get_llm(model_type, api_key):
    if model_type == "DeepSeek R1 (OpenRouter)":
        return ChatOpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=api_key,
            model="deepseek/deepseek-r1:free",
            temperature=0.3
        )
    elif model_type == "Gemini 2.5 Flash":
        return ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=api_key,
            temperature=0.1
        )
    return None
