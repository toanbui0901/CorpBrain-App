import os
import time
import tempfile
import pandas as pd
from datetime import datetime
import streamlit as st

# Import SDK Google
import google.generativeai as genai

from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain_community.vectorstores import FAISS
from langchain_core.documents import Document
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.document_loaders import Docx2txtLoader
from pypdf import PdfReader

DB_DIR = "faiss_index"
HISTORY_FILE = "file_history.csv"

# --- H√ÄM OCR B·∫∞NG GEMINI (SI√äU NH·∫∏ RAM) ---
def ocr_via_gemini(file_path, api_key):
    """
    Upload file l√™n Google, nh·ªù Gemini 1.5 Flash ƒë·ªçc n·ªôi dung tr·∫£ v·ªÅ text.
    """
    try:
        # C·∫•u h√¨nh API
        genai.configure(api_key=api_key)
        
        # 1. Upload file l√™n Google File API (L∆∞u t·∫°m)
        st.toast("‚òÅÔ∏è ƒêang g·ª≠i file scan l√™n Google ƒë·ªÉ ƒë·ªçc...", icon="üöÄ")
        sample_file = genai.upload_file(path=file_path, display_name="Scan Document")
        
        # ƒê·ª£i file s·∫µn s√†ng (Google c·∫ßn v√†i gi√¢y ƒë·ªÉ x·ª≠ l√Ω file)
        while sample_file.state.name == "PROCESSING":
            time.sleep(2)
            sample_file = genai.get_file(sample_file.name)
            
        if sample_file.state.name == "FAILED":
            return "L·ªói: Google kh√¥ng ƒë·ªçc ƒë∆∞·ª£c file n√†y."

        # 2. G·ªçi Model Flash ƒë·ªÉ tr√≠ch xu·∫•t vƒÉn b·∫£n
        model = genai.GenerativeModel(model_name="gemini-1.5-flash")
        
        response = model.generate_content([
            sample_file,
            "H√£y ƒë√≥ng vai m·ªôt c√¥ng c·ª• OCR ch√≠nh x√°c. Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t to√†n b·ªô vƒÉn b·∫£n c√≥ trong file PDF n√†y ra d·∫°ng text. Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng ti·∫øng Vi·ªát. Ch·ªâ tr·∫£ v·ªÅ n·ªôi dung vƒÉn b·∫£n, kh√¥ng th√™m l·ªùi d·∫´n."
        ])
        
        # 3. D·ªçn d·∫πp (X√≥a file tr√™n Cloud ƒë·ªÉ b·∫£o m·∫≠t)
        genai.delete_file(sample_file.name)
        
        return response.text
        
    except Exception as e:
        return f"L·ªói Cloud OCR: {str(e)}"

def read_pdf_smart(file_path, api_key):
    """
    Chi·∫øn thu·∫≠t:
    1. Th·ª≠ ƒë·ªçc nhanh b·∫±ng pypdf (cho file digital).
    2. N·∫øu √≠t ch·ªØ -> Coi l√† scan -> G·ªçi Gemini OCR.
    """
    text = ""
    try:
        reader = PdfReader(file_path)
        for page in reader.pages:
            t = page.extract_text()
            if t: text += t + "\n"
    except: pass

    # Ng∆∞·ª°ng ph√°t hi·ªán scan: N·∫øu trung b√¨nh m·ªói trang < 20 k√Ω t·ª±
    total_pages = len(reader.pages) if 'reader' in locals() and reader.pages else 1
    if len(text) < 20 * total_pages:
        st.info("üì∑ Ph√°t hi·ªán t√†i li·ªáu Scan. ƒêang k√≠ch ho·∫°t Gemini OCR (Cloud)...")
        # G·ªçi Gemini ƒë·ªçc
        text = ocr_via_gemini(file_path, api_key)
    
    return text

# --- H√ÄM X·ª¨ L√ù CH√çNH ---
def process_and_save(uploaded_file, meta_info, api_key):
    if not api_key:
        st.error("Thi·∫øu API Key!")
        return 0

    # L∆∞u file t·∫°m
    with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded_file.name.split('.')[-1]}") as tmp:
        tmp.write(uploaded_file.getbuffer())
        fpath = tmp.name

    # ƒê·ªçc n·ªôi dung
    text = ""
    if uploaded_file.name.endswith('.pdf'):
        text = read_pdf_smart(fpath, api_key)
    elif uploaded_file.name.endswith('.docx'):
        loader = Docx2txtLoader(fpath)
        docs = loader.load()
        text = "\n".join([d.page_content for d in docs])
    elif uploaded_file.name.endswith('.xlsx'):
        try:
            df = pd.read_excel(fpath)
            text = df.to_string(index=False)
        except: pass
    
    os.remove(fpath) # X√≥a file t·∫°m ngay
    
    if not text or not text.strip():
        st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c n·ªôi dung vƒÉn b·∫£n.")
        return 0

    # Metadata injection
    full_content = (
        f"METADATA >> [T√™n: {meta_info['doc_name']}] | [ƒê∆°n v·ªã: {meta_info['department']}] | [Ng√†y HL: {meta_info['effective_date']}]\n"
        f"N·ªòI DUNG:\n{text}"
    )
    doc = Document(page_content=full_content, metadata=meta_info)
    
    # Chunking
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    splits = splitter.split_documents([doc])

    # Embedding v√†o FAISS
    try:
        emb_func = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
        
        if os.path.exists(DB_DIR):
            try:
                old_db = FAISS.load_local(DB_DIR, emb_func, allow_dangerous_deserialization=True)
                new_db = FAISS.from_documents(splits, emb_func)
                old_db.merge_from(new_db)
                old_db.save_local(DB_DIR)
            except:
                # N·∫øu index c≈© l·ªói, t·∫°o m·ªõi ƒë√® l√™n
                db = FAISS.from_documents(splits, emb_func)
                db.save_local(DB_DIR)
        else:
            db = FAISS.from_documents(splits, emb_func)
            db.save_local(DB_DIR)
            
    except Exception as e:
        st.error(f"L·ªói Vector DB: {e}")
        return 0
    
    # Ghi log
    log_entry = {
        "File g·ªëc": uploaded_file.name,
        "T√™n vƒÉn b·∫£n": meta_info['doc_name'],
        "Ng√†y n·∫°p": datetime.now().strftime("%Y-%m-%d %H:%M")
    }
    if os.path.exists(HISTORY_FILE):
        df_hist = pd.read_csv(HISTORY_FILE)
        df_hist = pd.concat([df_hist, pd.DataFrame([log_entry])], ignore_index=True)
    else:
        df_hist = pd.DataFrame([log_entry])
    df_hist.to_csv(HISTORY_FILE, index=False)
    
    return len(splits)

def get_llm(model_type, api_key):
    # Lu√¥n d√πng Gemini cho nh·∫π
    if model_type == "Gemini 2.5 Flash":
        return ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key, temperature=0.1)
    elif model_type == "DeepSeek R1 (OpenRouter)":
        return ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=api_key) # Fallback t·∫°m v·ªÅ Gemini cho ·ªïn ƒë·ªãnh
    return None
